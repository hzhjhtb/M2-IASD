{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "y_YUqkutrdO-",
      "metadata": {
        "id": "y_YUqkutrdO-"
      },
      "source": [
        "# Segmentation\n",
        "\n",
        "In this notebook you will train and test a deep learning model to perform binray image segmentation. Segmentation is a very common tool in image analysis. In particular, binary segmentation is used to locate some particular elements in an image, which will be labeled in white while the rest of the image remains black, like in [this example](https://i.stack.imgur.com/i24FE.png).\n",
        "\n",
        "This notebook deals with Whole Slide Images (WSI). Whole slide imaging, also known as virtual microscopy, refers to scanning a complete microscope slide and creating a single high-resolution digital file. For more information, see [this introduction](https://www.mbfbioscience.com/whole-slide-imaging-analysis).\n",
        "\n",
        "\n",
        "Teaching assistant: romain.vo@mines-paristech.fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38cc29a8",
      "metadata": {
        "id": "38cc29a8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "import imageio.v2 as imageio\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5F1XWeSkLxcz",
      "metadata": {
        "id": "5F1XWeSkLxcz"
      },
      "source": [
        "## Data\n",
        "\n",
        "Drag and drop the tissue-20221017T082544Z-001.zip into the colab files. Once done run the cell below to unzip the files into the 'data' folder\n",
        "\n",
        "Have a look at the different images in the folder, both initial images and their associated binary mask. As you can see some of them are quite messy with dirt, pen marks... The objective of this work is to create a model to segment these WSI images to remove these unwanted details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LBXjAU-KL1_3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBXjAU-KL1_3",
        "outputId": "cc20e350-3116-4369-c551-457ed90b4d41"
      },
      "outputs": [],
      "source": [
        "!unzip tissue-20221017T082544Z-001.zip -d data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc28ac0c",
      "metadata": {
        "id": "fc28ac0c"
      },
      "source": [
        "# Fetching data\n",
        "\n",
        "First step is to implement functions to send data to the training and testing pipeline. To do so, we implement the class DataGeneratorTissue used to select patches of images by customising keras DataGenerator class.  \n",
        "\n",
        "The function `get_random_patch_coord` randomly selects the coordinates of an image's patch, or crop. A `patch_coord` point to the top left corner of the corresponding patch. Thus the coordinates [y, x] gives for a patch of size [h, w] the image's patch *image* [y:y+h, x:x+w].\n",
        "\n",
        "The function `choose_patch_coord` calls `get_random_patch_coord` and should return the coordinates of a patch with at most 70% of background labels (pixel value of 0 in label). If it cannot be achieved after 10 tryouts, the function should return the coordinates of the patch with the lowest background labels found.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f786f4a",
      "metadata": {
        "id": "1f786f4a"
      },
      "outputs": [],
      "source": [
        "class DataGeneratorTissue(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, path, prefix, batch_size,\n",
        "                 patch_size, nb_channels_in=3, nb_channels_out=1,\n",
        "                 geometric_augmentations=[], augmentation_ratio=None):\n",
        "\n",
        "        self.path = path\n",
        "        self.prefix = prefix\n",
        "        self.get_data_dict()\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.nb_channels_in = nb_channels_in\n",
        "        self.nb_channels_out = nb_channels_out\n",
        "        self.geometric_augmentations = []\n",
        "        self.augmentation_ratio = augmentation_ratio\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, batch_idx):\n",
        "        batch_data_idxs = self.data_idxs[batch_idx*self.batch_size:(batch_idx+1)*self.batch_size]\n",
        "        x, y = self.fetch_data(batch_data_idxs)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.data_idxs = np.arange(len(self.data))\n",
        "        np.random.shuffle(self.data_idxs)\n",
        "\n",
        "    def get_data_dict(self):\n",
        "        self.data = {}\n",
        "        for data_idx, image_name in enumerate(os.listdir(os.path.join(*[self.path, self.prefix, \"jpg\"]))):\n",
        "            self.data[data_idx] = image_name\n",
        "\n",
        "    def get_random_patch_coord(self, image_size):\n",
        "        '''\n",
        "        image_size: (height, width)\n",
        "        '''\n",
        "\n",
        "        ### TO BE IMPLEMENTED ### (hint: use np.random.randint)\n",
        "\n",
        "        #########################\n",
        "\n",
        "        return patch_coord\n",
        "\n",
        "    def choose_patch_coord(self, image_shape, label, threshold=0.7):\n",
        "        '''\n",
        "        image_shape: (height, width)\n",
        "        label: shape (height, width, channels)\n",
        "        '''\n",
        "\n",
        "        ### TO BE IMPLEMENTED ###\n",
        "\n",
        "        #########################\n",
        "\n",
        "        return best_patch_coord\n",
        "\n",
        "    def fetch_data(self, batch_data_idxs):\n",
        "        x = np.empty([self.batch_size, *self.patch_size, self.nb_channels_in])\n",
        "        y = np.empty([self.batch_size, *self.patch_size, self.nb_channels_out])\n",
        "\n",
        "        for idx, data_idx in enumerate(batch_data_idxs):\n",
        "            image_file_path = os.path.join(*[self.path, self.prefix, \"jpg\", self.data[data_idx]])\n",
        "            image = imageio.imread(image_file_path)\n",
        "\n",
        "            label_file_path = os.path.join(*[self.path, self.prefix, \"lbl\", self.data[data_idx]])\n",
        "            label = imageio.imread(label_file_path)\n",
        "\n",
        "            image = np.float32(image/255)\n",
        "            label = np.expand_dims(np.float32(label/255), axis=-1)\n",
        "\n",
        "            patch_coord = self.choose_patch_coord(list(image.shape[:2]), label)\n",
        "\n",
        "            image_patch = image[patch_coord[0]:patch_coord[0]+self.patch_size[0],\n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "            label_patch = label[patch_coord[0]:patch_coord[0]+self.patch_size[0],\n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "\n",
        "            if len(self.geometric_augmentations) != 0:\n",
        "                if np.random.binomial(1, self.augmentation_ratio) == 1:\n",
        "                    augm_idx = random.randint(0,len(self.geometric_augmentations)-1)\n",
        "                    image_patch, label_patch = self.geometric_augmentations[augm_idx](image_patch, label_patch)\n",
        "\n",
        "            x[idx:idx+1,...] = image_patch\n",
        "            y[idx:idx+1,...] = label_patch\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "973e10af",
      "metadata": {
        "id": "973e10af"
      },
      "source": [
        "# UNet model builder\n",
        "\n",
        "The deep learning model we will use is a U-Net model, which was initially introduced to perform segmentation on microscopy images (see [paper](https://arxiv.org/abs/1505.04597)).\n",
        "\n",
        "Implement the encoder and decoder parts of the UNet model with skip connections in the `build_unet_model` function using only `conv_block`, `up_sampler` and [`keras.layers.Concatenate`](https://keras.io/api/layers/merging_layers/concatenate/) functions.\n",
        "\n",
        "There are several ways of implementing this in Keras, here we will use what is called the [Functional API](https://keras.io/api/models/model/). The idea is to start from a *template input*, `keras.Input(shape=(..))`, and to define all the transformations this *input* undergoes. These transformations need to be implemented in the form of `keras` or  `tensorflow` chains of transformations (they are already implemented below).\n",
        "\n",
        "Once done, the model is build implicitely by wrapping the  `inputs` and `outputs` inside a `keras.Model`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Khv-eGV53PjH",
      "metadata": {
        "id": "Khv-eGV53PjH"
      },
      "outputs": [],
      "source": [
        "def build_very_simple_model(nb_channels_in,\n",
        "                            nb_channels_out,\n",
        "                            unet_filters,\n",
        "                            image_size=[None, None]):\n",
        "\n",
        "    inputs = keras.Input([*image_size, nb_channels_in])\n",
        "\n",
        "    x = keras.layers.Conv2D(filters=256,\n",
        "                            kernel_size=3,\n",
        "                            strides=1,\n",
        "                            padding='same',\n",
        "                            kernel_initializer='he_normal')(inputs)\n",
        "    x = keras.layers.ReLU()(x)\n",
        "\n",
        "    x = keras.layers.Conv2D(filters=1,\n",
        "                                kernel_size=3,\n",
        "                                strides=1,\n",
        "                                padding='same',\n",
        "                                kernel_initializer='he_normal')(x)\n",
        "    outputs = tf.math.sigmoid(x)\n",
        "\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbea0d76",
      "metadata": {
        "id": "fbea0d76"
      },
      "outputs": [],
      "source": [
        "def conv_block(filters, strides):\n",
        "    conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                                                        strides=1, padding=\"same\",\n",
        "                                                        kernel_initializer = \"he_normal\"),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.LeakyReLU(),\n",
        "                                    keras.layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                                                        strides=strides, padding=\"same\",\n",
        "                                                        kernel_initializer = \"he_normal\"),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.LeakyReLU()])\n",
        "    return conv_block\n",
        "\n",
        "def final_block(filters, last_activation):\n",
        "    conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3,\n",
        "                                                        strides=1, padding=\"same\",\n",
        "                                                        kernel_initializer = \"he_normal\"),\n",
        "                                    keras.layers.BatchNormalization(),\n",
        "                                    keras.layers.Activation(last_activation)])\n",
        "    return conv_block\n",
        "\n",
        "def up_sampler(filters):\n",
        "    up_sampler = keras.Sequential([keras.layers.Conv2DTranspose(filters=filters, kernel_size=2,\n",
        "                                                                strides=2, padding=\"valid\",\n",
        "                                                                kernel_initializer = \"he_normal\"),\n",
        "                                   keras.layers.BatchNormalization(),\n",
        "                                   keras.layers.LeakyReLU()])\n",
        "    return up_sampler\n",
        "\n",
        "def build_unet_model(nb_channels_in, nb_channels_out,\n",
        "                     unet_filters, last_activation,\n",
        "                     image_size=[None, None]):\n",
        "    inputs = keras.Input([*image_size, nb_channels_in])\n",
        "\n",
        "    skip = []\n",
        "\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "    # Encoder part\n",
        "\n",
        "    # Decoder part\n",
        "\n",
        "    #########################\n",
        "\n",
        "    outputs = final_block(nb_channels_out, last_activation)(x)\n",
        "\n",
        "    unet_model = keras.Model(inputs, outputs)\n",
        "    return unet_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee0ea60",
      "metadata": {
        "id": "dee0ea60"
      },
      "source": [
        "# Segmentation loss\n",
        "\n",
        "The loss used here is the Jaccard loss, also known as Intersection over Union. As we are working with binary images as outputs, we want to maximize the overlap area of ground truth and predicted masks (see [Wikipedia](https://fr.wikipedia.org/wiki/Indice_et_distance_de_Jaccard) for more details).\n",
        "\n",
        "Implement the computation of the cardinal of the intersection and the union between *y_true* and *y_pred*, stored in the variables *intersection* and *union* for the jaccard index-based loss. The function *K.sum()* should be sufficient to do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d6c8f7",
      "metadata": {
        "id": "10d6c8f7"
      },
      "outputs": [],
      "source": [
        "def jaccard_loss(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "\n",
        "    #########################\n",
        "\n",
        "    return 1 - (intersection + smooth) / (union + smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b79b93cd",
      "metadata": {
        "id": "b79b93cd"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "Data augmentation enables to generate new elements for our data set by applying some basic transformations to our images. For more examples, see [this tutorial](https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc15cdf5",
      "metadata": {
        "id": "bc15cdf5"
      },
      "outputs": [],
      "source": [
        "def flip_aug(image, label):\n",
        "    flipped_image = np.flip(image, axis=1)\n",
        "    flipped_label = np.flip(label, axis=1)\n",
        "    return flipped_image, flipped_label\n",
        "\n",
        "def rot_aug(image, label):\n",
        "    image_rotation = ndimage.rotate(image, angle=random.randint(low=-20, high=20))\n",
        "    label_rotation = ndimage.rotate(label, angle=random.randint(low=-20, high=20))\n",
        "    return image_rotation, label_rotation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ac71ebf",
      "metadata": {
        "id": "4ac71ebf"
      },
      "source": [
        "# Model's training\n",
        "\n",
        "Launch the training of a UNet with the given hyperparameters on the gpu \"gpu:/0\" (the first gpu visible by cuda).  \n",
        "A directory named \"models\", where are located the models' directories storing the data of the differents models trained, will be created. .  \n",
        "In a model's directory, named according the model's id and the timestamp of its training (a security to avoid accidental overwriting), are stored the *model_parameters.json*, *best_model_weights.h5* and *log.csv* files.  \n",
        "Nothing to implement, just run for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd27f3a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd27f3a7",
        "outputId": "8750b0bd-b6b3-4cc3-c73b-8a7922dd770f"
      },
      "outputs": [],
      "source": [
        "path = \"data/tissue\"\n",
        "\n",
        "models_dir = \"models\"\n",
        "if os.path.exists(models_dir) == False:\n",
        "    os.mkdir(models_dir)\n",
        "\n",
        "model_id = 1\n",
        "\n",
        "dt = datetime.now()\n",
        "timestamp = str(dt.hour) + ':' + str(dt.minute) + ':' + str(dt.second) + '-' + str(dt.day) + ':' + str(dt.month) + ':' + str(dt.year)\n",
        "model_name = \"modelID=\" + str(model_id) +  \"_timestamp=\" + timestamp\n",
        "\n",
        "model_dir = os.path.join(models_dir, model_name)\n",
        "if os.path.exists(model_dir) == False:\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "nb_channels_in = 3\n",
        "nb_channels_out = 1\n",
        "last_activation = \"sigmoid\"\n",
        "unet_filters = [8, 16, 32, 64]\n",
        "patch_size = [128, 128]\n",
        "batch_size = 5\n",
        "lr = 0.0001\n",
        "nb_epochs = 1\n",
        "\n",
        "model_parameters = {\"nb_channels_in\": nb_channels_in,\n",
        "                    \"nb_channels_out\": nb_channels_out,\n",
        "                    \"last_activation\": last_activation,\n",
        "                    \"unet_filters\": unet_filters,\n",
        "                    \"patch_size\": patch_size,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"lr\": lr,\n",
        "                    \"nb_epochs\": nb_epochs}\n",
        "\n",
        "json.dump(model_parameters, open(os.path.join(model_dir, \"model_parameters.json\"), \"w\"))\n",
        "\n",
        "model = build_unet_model(3, 1, unet_filters, \"sigmoid\", image_size = patch_size)\n",
        "model.summary()\n",
        "\n",
        "train_datagen = DataGeneratorTissue(path, \"train\", batch_size,\n",
        "                                    patch_size, 3, 1,\n",
        "                                    geometric_augmentations=[flip_aug, rot_aug], augmentation_ratio=0.2)\n",
        "\n",
        "val_datagen = DataGeneratorTissue(path, \"val\", batch_size,\n",
        "                                  patch_size, 3, 1)\n",
        "\n",
        "opt = keras.optimizers.Adam(lr)\n",
        "model.compile(optimizer=opt, loss=jaccard_loss)\n",
        "\n",
        "model_log_file_path = os.path.join(model_dir, \"log.csv\")\n",
        "best_model_weights_file_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.CSVLogger(model_log_file_path),\n",
        "    keras.callbacks.ModelCheckpoint(best_model_weights_file_path,\n",
        "                                    save_best_only=True, save_weights_only=True)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BDcgRxyrGiBY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDcgRxyrGiBY",
        "outputId": "915a7773-b7af-4d73-ccbe-489ecc41ec7b"
      },
      "outputs": [],
      "source": [
        "model.fit(train_datagen,\n",
        "          epochs=nb_epochs,\n",
        "          validation_data=val_datagen,\n",
        "          verbose=1,\n",
        "          callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e66fbfb",
      "metadata": {
        "id": "0e66fbfb"
      },
      "source": [
        "# Model's training summary\n",
        "\n",
        "Plot the training and validation loss.  \n",
        "Nothing to implement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42069cb3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "42069cb3",
        "outputId": "415791e3-dcdf-4076-fd24-e0aff7d32d77"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(model_log_file_path, sep=\",\")\n",
        "plt.plot(df[\"epoch\"], df[\"loss\"], \"r\", label=\"training loss\")\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"], \"b\", label=\"validation loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca5c9b9",
      "metadata": {
        "id": "6ca5c9b9"
      },
      "source": [
        "# Model's inference function\n",
        "\n",
        "*make_apply_unet_model* is the function to call to embeds a UNet model into a function in charge of the whole pipeline to get from an 8-bit image an 8-bit binary segmentation mask.  \n",
        "Implement the *apply_unet_model* function.\n",
        "Here the pipeline should include:  \n",
        "* a [0,1]-normalization  \n",
        "* a padding of the image (so that its dimension are 2^{unet_depth = len(unet_filters)-1} divisible)  \n",
        "* the application of the UNet model  \n",
        "* an unpadding of the UNet model's output (to retrieve the initial image dimensions)  \n",
        "* the conversion of the UNet model's output into a binary segmentation mask by taking the label with the highest probability for each pixel  \n",
        "\n",
        "The *pad_image* and *unpad_image* are already provided. The numpy function *np.where(condition, value if condition true, value if condition false)* should useful for an efficient conversion into a binary segmentation mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "914b9cb9",
      "metadata": {
        "id": "914b9cb9"
      },
      "outputs": [],
      "source": [
        "def pad_image(image, unet_depth):\n",
        "    shape = image.shape[:2]\n",
        "    if shape[0]%2**unet_depth != 0 or shape[1]%2**unet_depth != 0:\n",
        "        new_shape = [shape[0] + 2**unet_depth - shape[0]%2**unet_depth,\n",
        "                     shape[1] + 2**unet_depth - shape[1]%2**unet_depth]\n",
        "        new_image = np.empty([*new_shape, 3])\n",
        "        new_image[0:shape[0], 0:shape[1], :] = image[...]\n",
        "\n",
        "        new_image[0:shape[0],shape[1]:new_shape[1],:] = image[:,shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "        new_image[shape[0]:new_shape[0],0:shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],:,:]\n",
        "        new_image[shape[0]:new_shape[0],shape[1]:new_shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "\n",
        "        return new_image\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "def unpad_image(image, old_shape):\n",
        "    im_shape = image.shape[:2]\n",
        "    if im_shape[0] == old_shape[0] and im_shape[1] == old_shape[1]:\n",
        "        return image\n",
        "    else:\n",
        "        new_image = image[0:old_shape[0], 0:old_shape[1], :]\n",
        "        return new_image\n",
        "\n",
        "def apply_unet_model(unet_model, unet_depth, image):\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "\n",
        "    #########################\n",
        "    return segm\n",
        "\n",
        "def make_apply_unet_model(unet_model, unet_depth):\n",
        "    return lambda image: apply_unet_model(unet_model, unet_depth, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abaacc51",
      "metadata": {
        "id": "abaacc51"
      },
      "source": [
        "# Model's application on test dataset\n",
        "\n",
        "Apply a UNet model on test dataset images.  \n",
        "The model is chosen with its id."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hDlSZxcdl87E",
      "metadata": {
        "id": "hDlSZxcdl87E"
      },
      "outputs": [],
      "source": [
        "indexes_to_test = [8, 42]  # indexes in [0, 42]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oHDwnmhFDE5m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "oHDwnmhFDE5m",
        "outputId": "5f601efc-8b24-418f-df48-de59200a2764"
      },
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "model_idx = -1\n",
        "\n",
        "models_list = sorted(os.listdir(\"models\"))\n",
        "model_dir = os.path.join(\"models\", models_list[model_idx])\n",
        "\n",
        "with open(os.path.join(model_dir, \"model_parameters.json\"), \"r\") as model_parameters_file:\n",
        "    model_parameters = json.load(model_parameters_file)\n",
        "\n",
        "weights_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "model2 = build_unet_model(model_parameters[\"nb_channels_in\"],\n",
        "                          model_parameters[\"nb_channels_out\"],\n",
        "                          model_parameters[\"unet_filters\"],\n",
        "                          model_parameters[\"last_activation\"])\n",
        "\n",
        "model2.load_weights(weights_path)\n",
        "\n",
        "apply_model =  make_apply_unet_model(model2, len(model_parameters[\"unet_filters\"])-1)\n",
        "\n",
        "test_images_dir = os.path.join(path, \"test\")\n",
        "test_images_filenames = os.listdir(os.path.join(test_images_dir, \"jpg\"))\n",
        "\n",
        "for test_image_idx in indexes_to_test:\n",
        "\n",
        "  image = imageio.imread(os.path.join(*[test_images_dir, \"jpg\", test_images_filenames[test_image_idx]]))\n",
        "  label = imageio.imread(os.path.join(*[test_images_dir, \"lbl\", test_images_filenames[test_image_idx]]))\n",
        "\n",
        "  segm = apply_model(image)\n",
        "\n",
        "  fig, ax = plt.subplots(1, 3, figsize=(18, 18))\n",
        "\n",
        "  ax[0].imshow(image)\n",
        "  ax[0].set_title(\"Input\")\n",
        "  ax[1].imshow(segm, cmap=\"gray\")\n",
        "  ax[1].set_title(\"Prediction\")\n",
        "  ax[2].imshow(label, cmap=\"gray\")\n",
        "  ax[2].set_title(\"Target\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9SiCSAa_mOo2",
      "metadata": {
        "id": "9SiCSAa_mOo2"
      },
      "source": [
        "# Interpretation\n",
        "\n",
        "Change values of indexes to test with different images.\n",
        "\n",
        "What do you think about the results? What seems to work? What limitations do you see?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 ('keras-gpu-py37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11 (default, Jul 27 2021, 09:42:29) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1cd8fa715f4e783bb81f945723edfe74554df81b9cdc3abfedca690bf5dda2c7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
